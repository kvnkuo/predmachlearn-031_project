---
title: "The predictions of Weight Lifting Exercise dataset"
author: "Kevin Kuo"
date: "2015/08/20"
output: html_document:
    pandoc_args: [
      "+RTS", "-K64m",
      "-RTS"
    ]
---

```{r loadsavedrds, echo=FALSE}
pmldata = readRDS("pmldata.rds")
pmldata_test = readRDS("pmldata_test.rds")
training = readRDS("training.rds")
testing = readRDS("testing.rds")
modFit_rf = readRDS("modFit_rf.rds")
modFit_ctree = readRDS("modFit_ctree.rds")
pred_ctree = readRDS("pred_ctree.rds")
pred_ctree_test = readRDS("pred_ctree_test.rds")
pred_rf = readRDS("pred_rf.rds")
library(caret)
options(warn=-1)
```
The primary goal of this report is to find a appropriate model to correctly predict the outcomes of the Weight Lifting Exercise dataset. The WLE dataset comes from Velloso, E. et al. [**R. 1**].

We start by reading the data into R and perform some basic explorarations.
```{r, eval=FALSE}
pmldata <- read.csv("pml-training.csv",
                      dec=".", stringsAsFactors = FALSE, 
                      allowEscapes = TRUE, sep=",", 
                      quote = "\"", header=TRUE, fill = TRUE)
```

The dimension of the whole dataset
```{r dimpmldata}
dim(pmldata)
```

The prediction is to output classification results. So, we must make sure the classe column is of factor type.
```{r factorclasse, eval=FALSE}
pmldata$classe <- factor(pmldata$classe)
```

Before doing the simulation, we import the parallel processing library to speed up the processing.
```{r, eval=FALSE}
library(doParallel)
registerDoParallel(cores=4)
```

The whole data will be divided into two groups: traing(80%) and testing(20%).
```{r, eval=FALSE}
library(caret)
inTrain <- createDataPartition(y=pmldata$classe, p=0.8, list=FALSE)
training <- pmldata[inTrain,]
testing <- pmldata[-inTrain,]
```

```{r dimtraining}
dim(training)
```

Both selection of model and method for feature extraction are also inspired by the paper [**R. 1**]. We use Random Forest method to build our model. The original method for feature extraction is based on the followings rules:  
1. In the belt, were selected the mean and variance of the roll, maximum, range and variance of the accelerometer vector, variance of the gyro and variance of the magnetometer.  
2. the  arm,  the  variance  of  the  accelerometer  vector  and  the maximum and minimum of the magnetometer were selected.  
3. In the dumbbell, the selected features were the maximum of the  acceleration,  variance  of  the  gyro  and  maximum  and minimum of the magnetometer, while in the glove, the sum of  the  pitch  and  the  maximum  and  minimum  of  the  gyro were selected.  

Instead of using max, min, sum, mean, var and range of the measured data to build the model, we try an alternative method. For max, min, sum and range values, we simply use the measured data as equivalent ones. For var values, we use the square of the measured data as equivalent ones. For example, in the belt, we use roll_belt instead of mean(roll_belt) in specific time window. Also, in the belt, we use roll_belt^2 instead of var(roll_belt) in specific time window. Our simplified assumption is based on the idea that var is linear equivalent to square.  

Following is the model call(to save processing time, we load the saved one.)
```{r call}
modFit_rf$call
```

The confusion matrix of trained model is listed below. The error rates are not bad.
```{r final Model}
modFit_rf$finalModel$confusion
```

We investigate the mode with testing data
```{r predictionwithrf, eval=FALSE}
pred_rf <- predict(modFit_rf, testing)
```
 and check it with confusion matrix.
```{r pred)rfconfusnmatx}
# Confusion matrix
confusionMatrix(pred_rf, testing$classe)
```
The error rates approximately match with error rates in the training data. The model's accuracy is 98.8% and its 95% C.I. is (0.9841, 0.9912). Also, the sensitivity and specificity for each outcome class are both high(>= 98%). We can conclude that the model's performance is acceptable. Let's proceed to the final step to predict the test data.

Now, we load the test data 
```{r readtestdata, eval=FALSE}
pmldata_test <- read.csv("pml-testing.csv",
                    dec=".", stringsAsFactors = FALSE, 
                    allowEscapes = TRUE, sep=",", 
                    quote = "\"", header=TRUE, fill = TRUE)
```
and perform the prediction.
```{r predicttestdata}
pred_rf_test <- predict(modFit_rf, pmldata_test)

pred_rf_test
```

Note: We also use Conditional Inference Trees method to build our model as in **a. 2**, **a. 3**. The model's accuracy is about 89.6% with 95% C.I. from 88.6% to 90.5%). The sensitivity of Class B, Class C and Class D are all less than 90%, though the specificity are all larger than 96%. The predicted outcomes are not as good as the above ones. However, the predicted test results are the same as the results from the Random Forest based model.  

### Appendix
**a. 1** The main prediction model (Random Forest)
```{r, eval=FALSE}
modFit_rf <- train(
    classe ~ roll_belt +
        roll_belt ^ 2 +
        total_accel_belt +
        accel_belt_x ^ 2 +
        accel_belt_y ^ 2 +
        accel_belt_z ^ 2 +
        gyros_belt_x ^ 2 +
        gyros_belt_y ^ 2 +
        gyros_belt_z ^ 2 +
        magnet_belt_x ^ 2 +
        magnet_belt_y ^ 2 +
        magnet_belt_z ^ 2 +
        accel_arm_x ^ 2 +
        accel_arm_y ^ 2 +
        accel_arm_z ^ 2 +
        magnet_arm_x +
        magnet_arm_y +
        magnet_arm_z +
        total_accel_dumbbell +
        gyros_dumbbell_x ^ 2 +
        gyros_dumbbell_y ^ 2 +
        gyros_dumbbell_z ^ 2 +
        magnet_dumbbell_x +
        magnet_dumbbell_y +
        magnet_dumbbell_z +
        pitch_forearm +
        gyros_forearm_x +
        gyros_forearm_y +
        gyros_forearm_z
    , data = training, method = "rf", prox = FALSE
)
```

**a. 2** Another prediction model (Conditional Inference Trees)
```{r anotherpredmod}
modFit_ctree$call
```

```{r predictionctreeandcon, eval=FALSE}
pred_ctree <- predict(modFit_ctree, testing)
```

```{r anotherpredmodconfusnmatx}
# cross validation 
confusionMatrix(pred_ctree, testing$classe)
```

**a. 3** Apply previous ctree model to test data (20 test cases)
```{r applyanothermodtotestdata}
pred_ctree_test <- predict(modFit_ctree, pmldata_test)

pred_ctree_test
```

### Reference

**R. 1**
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.
Read more: http://groupware.les.inf.puc-rio.br/har#wle_paper_section#ixzz3jKxnqNYs
